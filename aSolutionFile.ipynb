{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Beleg Prescriptive Analytics with Python <br>- Jannis Kaliske (4886335) -\n",
    "Traveling Salesman Problem with precedence constraints with<br>\n",
    "TabuSearch - MetaHeuristic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das vorgestellte logistische Problem ist ein sogenanntes \"Traveling Salesman Problem with precedence constrains\". Diese Herausforderung der Planung basiert darauf, dass in einem Pool eine gewisse Anzahl an Anlaufpunkte gegeben sind. Es muss jeder einzelne Punkt genau ein Mal angelaufen werden. Am Ende soll man zum Anfangspunkt zurückgekommen sein. Die Inputdaten beinhalten einerseits Dateiname, die Anzahl der anzulaufenden Punkte und die Wegematrix. Die Anzahl der Punkte unterscheidet sich von der Anzahl der Spalten/Zeilen der Wegematrix, da zusätzlich Start und Endpunkt in der Matrix enthalten sind. Demzufolge muss die Tour immer in Knoten 0 (erste Zeile) beginnen und endet immer in Knoten 20 (letzte Spalte). Knoten 20 ist der selbe Punkt wie Knoten 0, wurde jedoch hinzugefügt, um es mathematisch einfacher zu beschreiben. Zuletzt ist darauf hinzuweisen, dass gewissen Verbindungen eine Bewertung von \"-1\" aufweisen, was einen verbotenen Weg darstellt -> gewisse Ristriktionen im Traveling Salesman Problem: precedence constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine kurze Übersicht der benötigten Dateien/Klassen:<br>\n",
    "-   SolutionFile.ipynb      --> gibt übersichtlich den Programmierverlauf an, den Start des Algorithmus bitte über die letzte Codezelle in diesem Dokument<br>\n",
    "-   InputData.py            --> mit Klasse InputData wird Wegematrix generiert<br>\n",
    "-   EvaluationLogsic.py     --> mit Klasse EvaluationLogic wird Evaluierung einer Permutation durchgeführt<br>\n",
    "-   BestStartSolution.py    --> mit Klasse bestStartSolution wird eine Startlösung generiert<br>\n",
    "-   Solver.py               --> mit Klasse Solver und den Funktionen generateNeighborhood, tabuSearch wird MetaHeuristik gestartet und gesteuert<br>\n",
    "-   OutputData.py           --> mit Klasse outputAlgorithm wird eine csv Datei entsprechend der Vorgaben generiert und in einem Unterordner (\"Solutions\") entsprechend der Namensvorgabe abgespeichert<br>\n",
    "-   Ordner TestInstanzen\n",
    "-   Ordner Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden werden die Wegematrizen in den Algorithmus geladen. Hierbei wird auf die DataFrame Funktion von dem Package Pandas zurückgegriffen, weil dieses eine relativ einfach zu handhabende Struktur aufweist. Es wurde ein eigenes .py Dokument erstellt, um eine übersichtliche Dateistruktur aufzubauen. Dieser InputData Klasse wird der Dateiname (path) als Variale übergeben.\n",
    "Die Testinstanzen sind in einem Unterordner gespeichert, deshalb muss dieser zuerst angewählt werden mit #[1]. Anschließend wird die Datei mit dem Package json geladen. Auf die anderen Variable abseits der Wegematrix wurde verzichtet, da die Länge/Anlaufpunktzahl auch einfach über die Länge der Matrix einer beliebigen Reihe errechnet werden kann.\n",
    "<br><br>\n",
    "Für die Nutzung des Algorithmus mit den Testdaten bitte diese Dateien unbedingt in de Unterordner \"Testinstanzen\" kopieren. \n",
    "<br><br>\n",
    "In #[2] wird die Achsenbeschriftung generiert, damit das Handhaben mit dem DataFrame später einfacher wird<br>\n",
    "In #[3] wird die in self.data gespeicherte matrix in ein Dataframe geladen und die Achsenbeschriftung übergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##InputData.py\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class InputData:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        #Eingabe des Verzeichnisses der Touren-Daten\n",
    "        self.path = path\n",
    "        self.DataLoad()\n",
    "\n",
    "    def DataLoad(self):\n",
    "        var = ['Testinstanzen']\n",
    "        var.append(self.path)\n",
    "\n",
    "        #[1]    #Eingabe des Verzeichnisses der Touren-Daten\n",
    "        path = '\\\\'.join(var)\n",
    "\n",
    "        #Einlesen der Daten aus der Touren-Daten-Datei und abspeichern in Variable \"data\"\n",
    "        with open(path) as f:\n",
    "            inputData = json.load(f)\n",
    "\n",
    "        #Abspeichern der Daten\n",
    "        self.data = inputData['Distances']\n",
    "\n",
    "        #[2] #Generierung eines Arrays mit den Zahlen 0-(Anzahl Punkte im Tourenplan) zur Achsenbeschriftung, um eindeutiger und einfacher Matrix nachvollziehen zu können\n",
    "        axis = [i for i in range(len(self.data[0]))]\n",
    "\n",
    "        #[3] #Erstellung einer Matrix mittels Pandas-DataFrame, da mit diesem Kontrukt relativ leicht gearbeitet werden kann\n",
    "        self.matrix = pd.DataFrame()\n",
    "        for row in self.data:\n",
    "            self.matrix = pd.DataFrame(self.data, columns = axis, index = axis) #Einfügen der Daten mit Beschriftung der Achsen x,y \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem der Input generiert wurde, muss der Evaluierungsalgorithmus gecoded werden, der mit der Kostenfunktion die Güte einer variablen Permutation bestimmt.\n",
    "Dazu wurde die Datei EvaluationLogic.py geschrieben. Für die Algorithmus ist die Permutation (order) und die Wegematrix (matrix) wichtig, die ihm als Variablen übergeben werden. Bitte folgende Notizen im Code lesen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##EvaluationLogic.py\n",
    "import math\n",
    "\n",
    "class EvaluationLogic:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.path_sum = 0\n",
    "\n",
    "    def SolutionFinder(self, order, matrix):    \n",
    "    #Einführen von Lauf-/Zählvariablen\n",
    "        self.path_sum = 0   #Gibt die Summe der Wegkosten an\n",
    "        i = 0               #Iteriert wird über jedes Element des wieder zusammengesetzten Arrays order\n",
    "        zaehlvariable = 1   #Wird benötigt, um Abbruchkriterium einzubauen, da sonst ein Fehler geworfen wird, wenn Iteration beim letzten Element ist, da in for-Schleife die Wegkosten\n",
    "                            #vom aktuellen Element zum nächsten Element im Array aufsummiert werden. Beim letzten Element im Array gibt es allerdings kein darauffolgendes Element.\n",
    "                            #deshalb wird ein Abbruchkriterium 'if zaehlvariable == len(data[0])' eingebaut\n",
    "\n",
    "        for i in order: #über jedes Element im Array order iteriert\n",
    "            if zaehlvariable == len(matrix[0]): #Abbruchkriterium\n",
    "                break #wenn dies eintritt, wird for-Schleife abgebrochen und der Code außerhalb fortgesetzt\n",
    "            elif matrix.iloc[i, order[zaehlvariable]] == -1: #Zweites Abbruchkriterium: wenn eine Verbindung eine Bewertun von '-1' hat, bedeutet dies, dass diese Verbindung unzulässig ist.\n",
    "                self.path_sum = math.inf #wenn Verbindung unzulässig, wird den Wegkosten dieser Permutation der WErt Unendlich zugewiesen und for-Schleife abgebrochen, nächste Permutation wird gestartet\n",
    "                break\n",
    "            else: #wenn kein Abbruchkriterium erfüllt, wird folgender Code ausgeführt\n",
    "                self.path_sum = self.path_sum + matrix.iloc[i, order[zaehlvariable]]  #Wegkosten werden kumuliert, indem zu den bisherigen Wegkosten die Kantenbewertung vom Punkt i zum darauffolgenden Punkt im Array addiert werden\n",
    "                                                                        #hierbei muss allerdings der darauffolgende Punkt mit 'order[zaehlvariable]' angesprochen werden, da 'i+1' lediglich zur inkrementellen Erhöhung \n",
    "                                                                        #des Wertes i führt und nicht zur nächsten Stelle im Array. Dafür wurde die Zählvariable 'zaehlvariable' eingeführt\n",
    "                zaehlvariable += 1 #Zählvariable inkrementell erhöhen, für nächsten Iterationsschritt\n",
    "        return self.path_sum \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem Input und Evaluierung einer Lösung implementiert wurden, kann nun eine erste Startlösung generiert werden. Ich habe mich hierbei für die Auswahl der besten Permutation aus drei verscheidenen Generierungen von Startlösungen entschieden: FirstComeForstServe (FCFS), Zufallsgenerierung, ShortestNextWayTime (aka ShortestProcessingTime). Die Generierung der FCFS Permutation ist sehr simpel und wird als erstes vorgenommen. Hierbei werden lediglich die Zahlen von 0 bis zum Endpunkt aufsteigend aufgelistet. Dies entspricht der Regel FCFS, die besagt, dass der Erste zuerst angenmmen wird und anschließend der zweite, anhand der Nummerierung wird dies deutlich. <br>\n",
    "Anschließend wurde die Zufallsgenerierung implementiert. Diese ist folgenden ausschnittsweise dargestellt: es werden zufällig 200 Zahlen generiert, die anschließend als Seeds benutzt werden, um 200 Permutationen zu erstellen, die anschließend auf ihre Güte mittles EvaluationLogic geprüft werden. Die beste Permutation wird an den startSolutionPool weitergegeben, der alle besten Lösungen der drei StartAlgorithmen aufnimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #generate random solutions, 200 zufällige Zahlen mit seed jedoch reproduzierbar\n",
    "        random.seed(self.seed)\n",
    "        random_numbers = [random.randint(0, 10000) for x in range(200)]\n",
    "        randomZwischenspeicher = []\n",
    "        for i in random_numbers:#nutze alle Zahlen als unterschiedliche Seeds\n",
    "            #Generierung eines Arrays mit den Zahlen 0-(Anzahl Punkte im Tourenplan) zur Achsenbeschriftung, um eindeutiger und einfacher Matrix nachvollziehen zu können\n",
    "            axis = [i for i in range(len(self.matrix[0]))]\n",
    "\n",
    "            #Aus Achsenbeschriftung werden Start- und Endpunkt gelöscht, da diese immer an der selben Stelle sein müssen und beim Zufallsgenerieren sonst nicht End- und Anfangspunkt wären\n",
    "            axis.remove(0)\n",
    "            axis.remove(len(self.matrix[0]) - 1)\n",
    "            size=len(self.matrix)\n",
    "\n",
    "            #Randomisiert wird der Mittelteil des Arrays gemischt, um eine zufällige Lösung zu erzeugen\n",
    "            first_order = random.sample(axis, len(self.matrix[0])-2)\n",
    "\n",
    "            #Array wird wieder zusammengesetzt, indem Start- und Endpunkt hinzugefügt werden. Dadurch kann sichergestellt werden, dass Punkt 0 immer Anfang und Ende darstellt\n",
    "            order = [0]\n",
    "            for k in first_order:\n",
    "                order.append(k)\n",
    "            order.append(size-1)\n",
    "\n",
    "            if len(randomZwischenspeicher) == 0:\n",
    "                randomZwischenspeicher.append(order)\n",
    "            else:\n",
    "                if EvaluationLogic().SolutionFinder(order, self.matrix) < EvaluationLogic().SolutionFinder(randomZwischenspeicher[-1], self.matrix):\n",
    "                    randomZwischenspeicher.append(order)\n",
    "\n",
    "        self.startSolutionPool.append(deepcopy(randomZwischenspeicher[-1])) \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuletzt wird über ShortestProcessingTime eine Lösung generiert: für jeden Punkt wird der Nachfolger ausgewählt, der den kürzesten Weg hat. Dafür wurden zuerst alle Wegbewertungen von \"-1\" auf math.inf gesetzt, um einen unendlich hohen Wert zu erzeugen. Dies ist nötig, da bei der Suche nach dem kürzesten Weg eine Wegbewertung von -1 selbstverständlich als die beste Lösung erkannt wird (#[1]). Zudem wird dies auch mit der Hauptdiagonalen gemacht, die diese Bewertungen null sind und zu cycling führen würden. <br>\n",
    "Anschließend wird beginnend in der ersten Zeile nach dem Nachfolger gesucht, der die geringste Wegbewertung hat. Dieser wird anschließend über die index-Funktion angepeilt und als neue Start-Zeile gewählt. Zuvor wird allerdings diese Spalte gelöscht, da dieser Punkt nun angelaufen wurde. Nach dieser Regel wird bis zum Ende durchgelaufen und die finale Permutation mit Start und Endpunkten wieder versehen (#[2]). Dies ist nötig, da diese zuvor entfernt wurden, damit der Algorithmus den letzten Punkt (20) bereits vorher wahrnimmt. Da dies der Zielpunkt sein muss, wird hier vorgesorgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #generate ShortestProcessingTime\n",
    "        matrice = deepcopy(self.matrix)\n",
    "\n",
    "        for i in range(len(matrice[0])-1):\n",
    "            matrice[i][i] = math.inf #soll anlaufen des selben Punktes verhindern\n",
    "        matrice.replace(-1, math.inf, inplace = True) #setze unmögliche Weglängen auf unenedlich\n",
    "\n",
    "        reihenfolge= []\n",
    "        zeile = 0\n",
    "        i = 0\n",
    "\n",
    "        #letze Spalte löschen, um vorzeitiges Ende zu verhindern (letzter Anlaufpunkt ist immer die letzte Spalte)\n",
    "        matrice.drop(matrice.tail(1).index,inplace=True)\n",
    "        matrice = matrice.iloc[: , :-1] \n",
    "        lenght = len(matrice[0]-1)\n",
    "\n",
    "        while i < (lenght-1): #suche für jede Zeile nach dem besten Nachfolger mit der geringsten Wegbewertung\n",
    "            matrice.iloc[zeile].idxmin()\n",
    "            zeile_alt=deepcopy(zeile)\n",
    "            reihenfolge.append(matrice.loc[zeile].idxmin())\n",
    "        \n",
    "            zeile = matrice.loc[zeile].idxmin()\n",
    "            del matrice[zeile_alt] #lösche angelaufenen Punkt aus Matrix (Spalte)\n",
    "            i+=1\n",
    "\n",
    "        reihenfolge.append(len(matrice))\n",
    "        reihenfolge.insert(0, 0)\n",
    "\n",
    "        self.startSolutionPool.append(deepcopy(reihenfolge)) \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am Ende werden lediglich die drei Werte aus dem startSolutionPool verglichen und der geringste Wert (durch EvaluationLogic ausgewertet) als beste StartPermutation zurückgegeben (siehe BestStartSolution.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend startet der eigentliche Part: nach der Problem-Implementierung und der InitialLösungsGenerierung wird nun die InitialLösung an die MetaHeuristik weitergegeben. Neben der InitialLösung, dem Path (Name der Testinstanz) wird der MetaHeuristik zwei Parameter und die Wegematrix mitgegeben. Damit kann der TabuSearch Algorithmus gestartet werden. Die veränderbaren Parameter sind 1) maxTabuListLength und 2) maxIterations. 1) wirk hierbei als Intensivierungs- und Diversifikations Instrument und steuert, welche Tausche nicht erlaubt werden (mehr dazu im Folgenden). 2) Gibt an, wieviele Iterationen pro Nachbarschaft pro TabuSearch Iteration durchgeführt werden sollen. Beides hat Einfluss darauf, wie schnell und gut Lösungen gefunden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst jedoch einige Hinweise und Erklärungen zur verwendeten MetaHeuristik - TabuSearch. Die Idee von TabuSearch ist relativ simpel. Es wird eine Liste instanziiert, die bereits getätigte Tausche verbietet und so eine Rückkehr zu einem lokalen Optimum verhindern soll. Solange ein gewisses Abbruchkriterium nicht erreicht ist, werden mögliche Lösungen aus der Nachbarschaftssuche gesammelt und geprüft, ob sie tabu sind (in TabuListe enthalten) oder ob ein gewisses Aspirationskriterium erfüllt ist, die die TabuListe umgeht. <br><br>\n",
    "Im Folgenden werden zwei Codebeispiele gezeigt, die eine mögliche Implementierung der Metaheuristik zeigen: die erste Version ist eine etwas leistungsfähigere, jedoch nicht so akkurate Implementierung von TabuSearch. Genauer gesagt werden die TabuListe die generierten Permutationen aufgenommen. Wenn der Algorithmus eine Permutation als die beste der Nachbarschaft einstuft, fügt er sie der TabuListe hinzu und in der nächsten Iteration darf diese Permutation nicht erreicht werden. Bitte beachten Sie die Kommentare besonders am Anfang:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diese Version von TabuSearch entspricht NICHT vollständig der Idee, da die Permutationen als tabu abgespeichert werden.\n",
    "#Diese Version soll nur der Anschauung dienen und liegt dem Beleg zwar bei, soll jedoch NICHT als finale Abgabe verstanden werden.\n",
    "#Diese Version liegt dem Beleg bei und nutzt bei den File-Namen immer \"Part...\", damit keine Verwechslungen entstehen\n",
    "def tabuSearch(self, firstSolution, matrix, path, maxTabuListLength=5, seedf = 50):\n",
    "        self.firstSolution = firstSolution\n",
    "        self.matrix = matrix\n",
    "        self.path = path\n",
    "        tabuList2 = [deepcopy(firstSolution)]\n",
    "        Solution = deepcopy(firstSolution)\n",
    "        self.solutPoool.append(deepcopy(firstSolution))\n",
    "        self.maxTabuListLength = maxTabuListLength\n",
    "        self.seedf = seedf\n",
    "        time_needed=default_timer()\n",
    "        timer = 0\n",
    "        iteration = 1\n",
    "\n",
    "        if len(self.matrix[0])<50:\n",
    "            maxTabuSearchTime = 28\n",
    "        else:\n",
    "            maxTabuSearchTime = 290\n",
    "            \n",
    "        while timer < maxTabuSearchTime:\n",
    "            print(f\"\\nTabu-Search, Iteration {iteration}\")\n",
    "            iteration+=1\n",
    "\n",
    "            while len(tabuList2) > self.maxTabuListLength:\n",
    "                tabuList2.pop(0)\n",
    "\n",
    "            di = self.generateNeighboorhood(deepcopy(Solution), self.matrix, tabuList2, type='insertion', maxIterations=1000, seed=self.seedf)\n",
    "            ds = self.generateNeighboorhood(deepcopy(Solution), self.matrix, tabuList2, type='swap', maxIterations=1000, seed=self.seedf)\n",
    "\n",
    "            if EvaluationLogic().SolutionFinder(di, self.matrix) < EvaluationLogic().SolutionFinder(ds, self.matrix):   \n",
    "                Solution=deepcopy(di)\n",
    "                tabuList2.append(Solution)\n",
    "                self.solutPoool.append(deepcopy(Solution))\n",
    "\n",
    "            else:\n",
    "                Solution=deepcopy(ds)                \n",
    "                tabuList2.append(Solution)\n",
    "                self.solutPoool.append(deepcopy(Solution))\n",
    "\n",
    "            self.solutPoool.append(deepcopy(Solution))\n",
    "            timer = default_timer() - time_needed \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Version entspricht nicht ganz der Idee der MetaHeuristik, denn diese besgt, dass die Tausche selbst und nicht die Permutationen auf die TabuListe kommen sollen. Wenn Stelle 3 und 7 getauscht werden, sollen diese in den nächsten zB fünf Iterationen nicht wieder zurückgetauscht werden. Dies könnte zu sog. Cycling führen und immer das selbe lokale Optimum herbeiführen. Deshalb wurde noch eine zweite Variante implementiert, in der immer die Stellen der Tausche zurückgegeben werden und damit verboten werden. Dies macht auch die Implementierung des sog. Aspirationskriteriums sinnvoll, das laut der Litaratur meist besagt, dass ein Tausch trotz Verbot durch die TabuListe angenommen werden soll, wenn dadurch ein besserer Funktionswert entsteht [1]. Wenn man die Permutationen auf die TabuListe setzen würde, ist es unmöglich, einen besseren Funktionswert als bisher zu erreichen, wenn alle auf der TabuListe enthaltenen Werte (Permutationen) jedoch schon besucht wurden, da sie mal die besten Permutationen ihrer Nachbarschaft waren und bereits in den LösungsPool aufgenommen wurden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demzufolge wird nun die folgende TabuSearch Implmentierung erklärt. Im ersten Absatz werden lediglich lokale Laufvariablen, die TabuListe, gewisse Zwischenspeicher und der Lösungspool (self.solutPoool) angelegt. Anschließend werden die vereinbarten Zeiten für die Rechenzeit für die verschiedenen Probleme durch die Länge der Matrx bestimmt. Anschließend beginnt der eignetliche Algorithmus, solange (while-Bedingung) die gemessene Zeit unter der vereibarten Zeit liegt, soll TabuSearch iteriert werden. Es werden beide implementierten Nachbarschaften durchsucht (mehr dazu später) und anschließend die besten Ergebnisse dieser verglichen. Wenn die swap-Nachbarschaft zum besseren Ergebnis geführt hat, wird diese zum SolutionPool hinzugefügt und wird die neue StartPermutation für die nächste Tabu-Iteration und wenn nicht, dann die insertion-Lösung. Der bessere Tausch wird der TabuListe hinzufügt und darf in der nächsten Zeit nicht wiederholt werden (gesteuert durch User eingegebenen Parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Richtige TabuSearch Version, die auch implementiert wurde und in der letzten Zelle dieses Dokuments gestartet werden kann\n",
    "def tabuSearch(self, firstSolution, matrix, path, maxTabuListLength=5, maxIterations = 500):\n",
    "        self.firstSolution = firstSolution\n",
    "        self.matrix = matrix\n",
    "        self.path = path\n",
    "        tabuList = [] #Kurzzeitgedächtnis, nimmt entsprechend des Parameters eine gewisse Anzahl von durchgeführten Tauschen auf, die danach verboetn werden, bis sie rausgelöscht werden\n",
    "        Solution = deepcopy(firstSolution) #Startwert der ersten Iteration\n",
    "        self.solutPoool.append(deepcopy(firstSolution)) #Startlösung dem Langzeitgedächtnis aka LösungsPool hinzufügen\n",
    "        self.maxTabuListLength = maxTabuListLength\n",
    "        self.maxIterations = maxIterations\n",
    "        time_needed=default_timer() #starte Zeitabgleich/Timer\n",
    "        timer = 0\n",
    "        iteration = 1\n",
    "        tauschKombination = []\n",
    "        xtauschKombination = []\n",
    "\n",
    "        if len(self.matrix[0])<50: #Vorgabe der Rechenzeit abzüglich Pauschal Erfahrungswert an Sekunden zur Beendigung der letzten Iteration und Durchsuchung des Langzeitgedächtnisses nach der besten Lösung\n",
    "            maxTabuSearchTime = 28\n",
    "        else:\n",
    "            maxTabuSearchTime = 280\n",
    "        \n",
    "        while timer < maxTabuSearchTime: #Abbruchkriterium in Form eines Zeittimers\n",
    "            print(f\"\\nTabu-Search, Iteration {iteration}\")\n",
    "            iteration+=1\n",
    "            \n",
    "            #durchsuche beide Nachbarschaften nach der besten Lösung, die nicht auf tabuList ist ODER aspirationskriterium erfüllt\n",
    "            di = self.generateNeighboorhood(deepcopy(Solution), self.matrix, tabuList, type='swap', maxIterations=self.maxIterations)\n",
    "            ds = self.generateNeighboorhood(deepcopy(Solution), self.matrix, tabuList, type='insertion', maxIterations=self.maxIterations)\n",
    "            \n",
    "            #Auswertung der Ergebnisse\n",
    "            if EvaluationLogic().SolutionFinder(di, self.matrix) <= EvaluationLogic().SolutionFinder(ds[0], self.matrix):#falls swap Ergebnis besser oder gleich insertion Ergebnis ist:   \n",
    "                tauschKombination = []\n",
    "\n",
    "                for index, (first, second) in enumerate(zip(Solution, di)): #herausfinden, welche Tausche gemacht wurden, dazu wird die letzte Lösung mit der neuen Lösung verglichen und geänderte Stellen in tauschKombination gespeichert\n",
    "                    if first != second:\n",
    "                        tauschKombination.append(index)\n",
    "\n",
    "                xtauschKombination = tauschKombination[0], tauschKombination[1] #Liste wird in Tupel konvertiert, um eindeutig zuordnen zu können\n",
    "                tabuList.append(xtauschKombination) #Kurzzeitgedächtnis erweitern mit letztem Tupel\n",
    "                Solution=deepcopy(di) #Startwert der kommenden Iteration\n",
    "                self.solutPoool.append(deepcopy(Solution)) #dem Langzeitgedächtnis die lokale beste Lösung hinzufügen\n",
    "\n",
    "            else: #insertion Wert war besser\n",
    "                tauschKombination = deepcopy(ds[1]) #beste Tauschkombination ist an der zweiten Stelle der Rückgabeliste gepseichert (Besonderheit im Vergleich zu swap)\n",
    "                tabuList.append(tauschKombination) #Kurzzeitgedächtnis erweitern mit letztem Tupel\n",
    "                \n",
    "                Solution=deepcopy(ds[0]) #Startwert der kommenden Iteration\n",
    "                self.solutPoool.append(deepcopy(Solution))  #dem Langzeitgedächtnis die lokale beste Lösung hinzufügen\n",
    "\n",
    "            timer = default_timer() - time_needed #Timer aktualisieren\n",
    "\n",
    "\n",
    "            while len(tabuList) > self.maxTabuListLength: #wenn TabuListe länger als Vorgabewert, lösche den ältesten Eintrag an erster Stelle\n",
    "                tabuList.pop(0) \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Timer wird anschließend upgedated  und falls die maximale Länge der TabuListe erreicht wurde, wird das älteste Ergebnis aus der Liste gelöscht. Dieses Vorgehen wiederholt sich so lange bis der Timer über der Zeit ist. Ist dies der Fall, wird der komplette Lösungsraum (solutionPool) nach der besten Lösung abgesucht und zurückgegeben. Dazu wird die lokaleVariable Zwischenspeicher generiert, in die alle Wegzeiten hinzugefügt werden. Anschließend wird mit einer einfachen Funktion der Index des geringsten Werts aus der gesamten Liste gesucht. Dieser ist sogleich auch die Stelle von der zugehörigen Permutation im SolutionPool. Damit kann schnell die beste Permutation der gesamten Heuristik bestimmt und zurückgegeben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #Abbruchkriterium wurde erreicht, Zeit ist abgelaufen: durchsuche gesamten LangzeitGedächtnis - Lösungsraum\n",
    "        zwischenSpeicher = []\n",
    "        for i in self.solutPoool:\n",
    "            zwischenSpeicher.append(EvaluationLogic().SolutionFinder(i, self.matrix)) #errechne für alle in SolutionPool enthaltenen Lösungen die Weglänge\n",
    "\n",
    "        index_min = min(range(len(zwischenSpeicher)), key=zwischenSpeicher.__getitem__) #Suche nach dem Index mit dem geringsten Lösungswert\n",
    "        bestFinalSolution = deepcopy(self.solutPoool[index_min]) #die gesamte-beste Lösung\n",
    "\n",
    "        print(f'\\nDie beste globale Lösung der MetaHeuristik ist {bestFinalSolution} mit {EvaluationLogic().SolutionFinder(deepcopy(bestFinalSolution), self.matrix)}.')\n",
    "        print(f'Dafür hat die MetaHeuristik {timer} Sekunden an Rechenzeit benötigt.')\n",
    "\n",
    "        outputAlgorithm(bestFinalSolution, self.matrix, self.path).startOutput() #starte Output auf Basis der gesamt-besten Lösung\n",
    "        \n",
    "        return bestFinalSolution \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein wesentlicher Bestandteil der Heuristik ist die Suche in den Nachbarschaften. DIese wird im Folgenden erklärt. Entschieden wurde sich für zwei Nachbarschaften: swap und insertion. Beide werden in der selben Solver-Klasse der Datei Solver.py unter der Methode .generateNeighborhood() aufgerufen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Wesentlichen läuft bei der swap-Nachbarschaft alles darauf hinaus, dass jedes Element mit jedem anderen Element getauscht und ausgewertet wird. Da es sich hier um eine Symmetrie handelt, werden nur die Tausche durchgeführt für die i < j gilt. Dadurch kann sehr viel Rechenleistung gespart werden (der Tausch von Stelle 3 und 7 ergibt das Selbe wie der Tausch von 7 mit 3).<br>\n",
    "Es werden Indices festgelegt, welche Stellen getauscht werden. Anschließend wird getestet, ob dieser Tausch tabu ist oder nicht (Abgleich mit TabuListe) ODER ob das zuvor erwähnte Apsirationskriterium erreicht wird. Letzteres wird relativ simpel durch iterative Verbesserungen ermittelt: Variable aspirationskriterium hat den Anfangswert math.inf (unendlich) und nur verbessernde Werte werden aufgenommen und dürfen die TabuListe umgehen. Dieser Wert wird nach jeder Verbesserung überschrieben mit Funktionswert und Permutation. Dies wird solange durchgeführt, bis entweder die gesamte Nachbarschaft durchsucht wurde oder die Anzahl maxIterations, die der Funktion beim Aufruf mitgegeben wurde, erreicht wurde. Anschließend wird ähnlich wie zuvpr mittels \"zwischenspeicher\" die beste lokale Permutation gesucht, die entweder nicht tabu oder das aspirationskriterium erfüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path  \n",
    "        self.solutPoool = [] #Langzeitgedächtnis, nimmt langfristig alle lokal besten Lösungen auf\n",
    "        \n",
    "\n",
    "    def generateNeighboorhood(self, firstSolution, matrix, tabuList, type = 'swap', maxIterations=10000):\n",
    "        self.matrix = matrix\n",
    "        self.firstSolution = firstSolution\n",
    "        self.type = type\n",
    "        self.maxIterations = maxIterations\n",
    "        self.tabuList = tabuList\n",
    "        localBestSolution = []\n",
    "        it=0\n",
    "        #Aspirationskriterium initialisiert mit einem maximalen Wert und bei einer Verbesserung wird die List überschrieben\n",
    "        aspirationskriterium = [EvaluationLogic().SolutionFinder(deepcopy(firstSolution), self.matrix), deepcopy(firstSolution)]\n",
    "        \n",
    "\n",
    "        if type == \"swap\": #swap Nachbarschaft wird gestartet\n",
    "            localBestSolution.clear()\n",
    "\n",
    "            for i in range(1, len(self.firstSolution)-1):\n",
    "                for j in range(1, len(self.firstSolution)-1):\n",
    "                    if it == self.maxIterations:\n",
    "                        break\n",
    "                    else:\n",
    "                        it+=1\n",
    "                        if i < j:\n",
    "                            indexA = j\n",
    "                            indexB = i\n",
    "                            nextSolution = list(self.firstSolution) # create a copy of the permutation\n",
    "\n",
    "                            #swap der Punkte an den indice STellen wird vorgenommen\n",
    "                            nextSolution[indexA] = deepcopy(self.firstSolution[indexB])\n",
    "                            nextSolution[indexB] = deepcopy(self.firstSolution[indexA])\n",
    "\n",
    "                            tauschKombi = (i, j)\n",
    "                            \n",
    "                            #Abgleich mit TabuListe ODER Aspirationskriterium ist wahr, falls aktuelle Lösung besser als alle bisher, wird aspirationskriterium upgedated\n",
    "                            if (tauschKombi not in self.tabuList) or (EvaluationLogic().SolutionFinder(deepcopy(nextSolution), self.matrix) < aspirationskriterium[0])==True:\n",
    "                                    localBestSolution.append(nextSolution)\n",
    "                                    if aspirationskriterium[0] > EvaluationLogic().SolutionFinder(nextSolution, self.matrix):\n",
    "                                        aspirationskriterium[0] = EvaluationLogic().SolutionFinder(nextSolution, self.matrix)\n",
    "                                        aspirationskriterium[1] = nextSolution\n",
    "            \n",
    "            #durchsuchen der localBestSolution Liste nach der besten lokalen Lösung der Nachbarschaft\n",
    "            zwischenSpeicher = []\n",
    "            for i in localBestSolution:\n",
    "                zwischenSpeicher.append(EvaluationLogic().SolutionFinder(deepcopy(i), self.matrix))\n",
    "\n",
    "            index_min = min(range(len(zwischenSpeicher)), key=zwischenSpeicher.__getitem__) #Suche nach dem Index mit dem geringsten Lösungswert\n",
    "            singleLocalBestSolution = deepcopy(localBestSolution[index_min])\n",
    "\n",
    "            print(f'eine Weglänge von {EvaluationLogic().SolutionFinder(deepcopy(singleLocalBestSolution), self.matrix)} über {singleLocalBestSolution} wurde mit swap erreicht')\n",
    "            return singleLocalBestSolution \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zurückgegeben wird die beste Permutation der Nachbarschaft. Bisher wurde Folgendes noch nicht erwähnt: das Update der TabuListe erfolgt in der Funktion tabuSearch, nachdem die beste Nachbarschafts-Permutation erzeugt wurde. Für den Swap-Algorithmus ist dies sehr einfach, da durch eine kleine und einfache Logik jede Stelle der neuen Permutation wird der Stelle der vorherigen Permutation verglichen wird. Die Indices ergeben den durchgeführten Tausch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        tauschKombination = []\n",
    "\n",
    "        for index, (first, second) in enumerate(zip(Solution, di)): #herausfinden, welche Tausche gemacht wurden, dazu wird die letzte Lösung mit der neuen Lösung verglichen und geänderte Stellen in tauschKombination gespeichert\n",
    "            if first != second:\n",
    "                tauschKombination.append(index)\n",
    "\n",
    "        xtauschKombination = tauschKombination[0], tauschKombination[1] #Liste wird in Tupel konvertiert, um eindeutig zuordnen zu können \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies kann bei der Insertion jedoch nicht angewandt werden, die sich hier oftmals mehr als nur eine Stelle ändern. Insertion an sich wählt eine Zahl und eine Stelle aus. Diese Zahl wird anschließend an diese Stelle gerückt und der Rest aufgefüllt. Im Folgenden ist der Algorithmus dargestellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elif type == 'insertion': #insertion Nachbarschaft wird gestartet\n",
    "            nextPermut = []\n",
    "            nextPermuts = []\n",
    "            localBestSolution.clear()\n",
    "            firstSolutio = deepcopy(self.firstSolution)\n",
    "\n",
    "            for i in range(1, len(firstSolutio)-1):\n",
    "                for j in range(1, len(firstSolutio)-1):\n",
    "                    if it == self.maxIterations:\n",
    "                        break\n",
    "                    if i == j or i == j + 1:\n",
    "                        continue\n",
    "                    elif i<j:\n",
    "                        it+=1\n",
    "                        nextPermuts.clear()\n",
    "                        nextPermut.clear()\n",
    "                        indexA = deepcopy(i)\n",
    "                        indexB = deepcopy(j)\n",
    "\n",
    "                        for k in range(len(firstSolutio)):\n",
    "                            if k == i:\n",
    "                                continue\n",
    "                            nextPermut.append(deepcopy(firstSolutio[k]))\n",
    "                        nextPermut.insert(indexB, deepcopy(firstSolutio[i]))\n",
    "                        tauschKombi = (i, j) #TauschKombination, die am Ende an die TabuListe weitergegeben wird\n",
    "                        nextPermuts = [nextPermut, tauschKombi] #Liste besteht aus nächster Permutation und TauschKombination, da die tauschKombi an TabuSearch zurückgegeben werden muss, um TabuListe zu ergänzen\n",
    "\n",
    "                        #Abgleich mit TabuListe ODER Aspirationskriterium ist wahr, falls aktuelle Lösung besser als alle bisher, wird aspirationskriterium upgedated\n",
    "                        if (tauschKombi not in self.tabuList) or (EvaluationLogic().SolutionFinder(nextPermuts[0], self.matrix) < aspirationskriterium[0])==True:\n",
    "                            localBestSolution.append(deepcopy(nextPermuts))\n",
    "                            nextSolu = EvaluationLogic().SolutionFinder(nextPermuts[0], self.matrix)\n",
    "                            if aspirationskriterium[0] > nextSolu:\n",
    "                                aspirationskriterium[0] = nextSolu\n",
    "                                aspirationskriterium[1] = nextPermuts[0] \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für jedes Element an jeder Stelle wird die insertion durchgeführt, solange es nicht die maxIterations übersteigt. Am Ende sieht man die selbe Logik wie zuvor: Lösung wird dem lokalen SolutionPool hinzugefügt, sofern er nicht tabu ODER das Aspirationskriterium angenommen wird. Um nun jedoch die Stellen des besten Tauschs aus dem Pool herauszubekommen wird laufend verglichen, ob es einen besseren Wert als unendlich gibt und sobald dieser angenommen wird, wird dieser als neues apsiratoinskriterium auf der Listenstelle [0] übernommen. Jedoch ist die Besonderheit hier, dass gleichzeitig auch die Stellen der Indices/Tauschstellen übernommen werden und gemeinsam als Rückgabewert in der TabuSearchAlgorithmus zurückgegeben werden, um diese der TabuListe hinzuzufügen. Dabei entspricht Rückgabewert ds[1] die TauschKombination, die an die TabuListe weitergegeben wird und ds[0] der besten Permutation aus der Nachbarschaft insertion. Am Ende wird die Lösung dem solutPoool hinzugefügt, sofern dieser besser als die der swap Nachbarschaft ist. Dies geschieht hier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                tauschKombination = deepcopy(ds[1]) #beste Tauschkombination ist an der zweiten Stelle der Rückgabeliste gepseichert (Besonderheit im Vergleich zu swap)\n",
    "                tabuList.append(tauschKombination) #Kurzzeitgedächtnis erweitern mit letztem Tupel\n",
    "                \n",
    "                Solution=deepcopy(ds[0]) #Startwert der kommenden Iteration\n",
    "                self.solutPoool.append(deepcopy(Solution))  #dem Langzeitgedächtnis die lokale beste Lösung hinzufügen\n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine wichtige Erkenntnis ist, dass die Nachbarschaftssuche nicht immer verbessernde Werte zurückliefern muss, sondern aufgrund der TabuListe auch manchmal gar nicht kann. Es wird zwar in der Intensivierungsphase immer der beste Wert weitergeben, kommt es jedoch zu einem lokalen Minimum, wird dieser zwangsweise auf die TabuListe gesetzt und anschließend kann es dazu kommen, dass kein besserer Wert gefunden werden kann. Da der letzte übergebene Wert jedoch auf der TabuListe steht, muss der Algorithmus sich verschlechtern und entkommt sofern die TabuListe lang genug ist, dem lokalen Optimum. Dies ist praktisch auch sehr gut an den größeren logistischen Problemen zu erkennen. Bei der Datei 'br17.json' jedoch nicht, da hier zu viele Permutationen die selben sehr guten Ergebnisse liefern. Der Sinn dieses Vergehens ist simpel, dem lokalen Optimum zu entkommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abschließend wird das langfristige Gedächtnis aka solutPoool mit der selben einfachen Logik mit 'zwischenspeicher' komplett durchsucht und das globale Optium, das in dieser Rechenzeit mit der MetaHeuristik erreicht werden konnte, zurückgegeben. Zurückgegeben einerseits in Form von einem Output in der Konsole, aber auch gleichzeitig in Form der letzten Klasse: in der Datei OutputData.py mit der Klasse outputAlgorithm und der Funktion startOutput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #Abbruchkriterium wurde erreicht, Zeit ist abgelaufen: durchsuche gesamten LangzeitGedächtnis - Lösungsraum\n",
    "        zwischenSpeicher = []\n",
    "        for i in self.solutPoool:\n",
    "            zwischenSpeicher.append(EvaluationLogic().SolutionFinder(i, self.matrix)) #errechne für alle in SolutionPool enthaltenen Lösungen die Weglänge\n",
    "\n",
    "        index_min = min(range(len(zwischenSpeicher)), key=zwischenSpeicher.__getitem__) #Suche nach dem Index mit dem geringsten Lösungswert\n",
    "        bestFinalSolution = deepcopy(self.solutPoool[index_min]) #die gesamte-beste Lösung\n",
    "\n",
    "        print(f'\\nDie beste globale Lösung der MetaHeuristik ist {bestFinalSolution} mit {EvaluationLogic().SolutionFinder(deepcopy(bestFinalSolution), self.matrix)}.')\n",
    "        print(f'Dafür hat die MetaHeuristik {timer} Sekunden an Rechenzeit benötigt.')\n",
    "\n",
    "        outputAlgorithm(bestFinalSolution, self.matrix, self.path).startOutput() #starte Output auf Basis der gesamt-besten Lösung\n",
    "        \n",
    "        return bestFinalSolution\n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Klasse outputAlgorithm wird mit den Werten der finalen besten Permutation, der Wegematrix und dem Namen der Datei instanziiert. Der Algorithmus prüft zuerst, ob das Verzeichnis \\\\Solutions bereitsexistiert und falls nicht, wird dieses noch generiert. Bitte beachten Sie die Kommentare, die den Code erklären. Um eine einfacherere Ansicht zu erhalten, gehen Sie bitte in die Datei OutputData.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class\n",
    "    def startOutput(self):\n",
    "\n",
    "        if not os.path.exists('Solutions'):\n",
    "            os.mkdir('Solutions')\n",
    "\n",
    "        #Einführen von Zählvariablen zur Vorbereitung des Outputs der Lösung\n",
    "        zaehlvar = 1\n",
    "        writer_path = 'Solutions\\Solution-' + self.path.replace('.json', '') + '.csv' #Generieren des Output-Paths auf Basis der Input-Datei, dabei muss die Dateiendung der Input-Datei gelöscht werden\n",
    "        cum_sum = 0 #Einführen der kumulierten Summe zum Abspeichern der CSV-Datei\n",
    "\n",
    "        #Generierung einer neuen Datei oder Überschreibung einer bereits existierenden Lösung mit Feldnamen 'Id' und 'Distances'\n",
    "        with open(writer_path, 'w', newline='') as file: #'w' damit vorhandene Datei überschrieben/resettet wird, newline = '' damit keine Absätze nach jeder Zeile generiert werden\n",
    "            dw = csv.DictWriter(file, delimiter=';', fieldnames=['Id', 'Distance']) #Trennungszeichen ';' eingeführt und Feldnamen eingegeben\n",
    "            dw.writeheader()\n",
    "\n",
    "        #Output/CSV-Generierung mithilfe der besten Lösung/Permutation aus Solver-Algorithmus\n",
    "        for i in self.order_final: #Für jedes Element der finalen Lösung wird der Weg nochmals nachvollzogen und in CSV-Datei exportiert. Beschreibung der Schleife siehe Solver\n",
    "            if zaehlvar == len(self.matrix[0]):\n",
    "                cum_sum = cum_sum + self.matrix.iloc[i, self.order_final[(zaehlvar)-1]]   #Beim ersten Abbruchkriterium aufgrund des letzten Elementes des Arrays muss (order_final[(zaehlvar)-1) gecoded werden, \n",
    "                                                                                #da als letzte Instanz in der vorherigen Iteration die (zaehlvar) um eins erhöht wurde und dies rückgängig gemacht werden muss\n",
    "\n",
    "                with open(writer_path, mode='a', newline='') as file: #mode='a' damit die bereits existierende CSV-Datei nur erweitert (appended) wird. Ein 'w' würde alle bisherigen Einträge löschen\n",
    "                    write_row = csv.writer(file, delimiter=';')\n",
    "                    write_row.writerow([i, cum_sum])\n",
    "                break\n",
    "            elif self.matrix.iloc[i, self.order_final[zaehlvar]] == -1:\n",
    "                with open(writer_path, mode='a', newline='') as file: #mode='a' damit die bereits existierende CSV-Datei nur erweitert (appended) wird. Ein 'w' würde alle bisherigen Einträge löschen\n",
    "                    write_row = csv.writer(file, delimiter=';')\n",
    "                    write_row.writerow(['Path is not valid']) #Abbruchkriterium falls 'ideale Lösung' des Solvers nicht erlaubt ist \n",
    "                zaehlvar +=1\n",
    "                break    \n",
    "            else:\n",
    "                with open(writer_path, mode='a', newline='') as file: #mode='a' damit die bereits existierende CSV-Datei nur erweitert (appended) wird. Ein 'w' würde alle bisherigen Einträge löschen\n",
    "                    write_row = csv.writer(file, delimiter=';')\n",
    "                    write_row.writerow([i, cum_sum])\n",
    "\n",
    "                cum_sum = cum_sum + self.matrix.iloc[i, self.order_final[zaehlvar]]\n",
    "                zaehlvar += 1 \n",
    "\\\\ #diese zwei Zeichen bitte nicht beachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Output Datei, die erzeugt wird ist entsprechend den Vorgaben eine .csv Textdatei, die mit Semikolon separiert einerseits die KnotenID und danach die kumulierte Distanz angibt. Als Beispiel ein Output für br17.json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id;Distance\n",
    "0;0\n",
    "6;8\n",
    "3;14\n",
    "4;14\n",
    "15;20\n",
    "5;20\n",
    "14;20\n",
    "9;28\n",
    "13;31\n",
    "2;31\n",
    "12;34\n",
    "1;34\n",
    "10;34\n",
    "8;39\n",
    "16;39\n",
    "7;39\n",
    "11;44\n",
    "17;44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die besten Werte, die während der gesamten Erprobungszeit erreicht wurden sind folgende:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br17.json:\n",
    "39      mit     [0, 16, 8, 7, 4, 3, 14, 6, 15, 5, 1, 12, 9, 10, 13, 2, 11, 17]\n",
    "\n",
    "ESC25.json:\n",
    "1836    mit     [0, 1, 12, 25, 3, 9, 22, 23, 24, 21, 17, 11, 16, 2, 13, 20, 8, 10, 19, 5, 7, 14, 6, 4, 18, 15, 26]\n",
    "\n",
    "ft70.json:\n",
    "40867   mit     [0, 1, 60, 14, 63, 66, 64, 69, 65, 68, 67, 48, 43, 49, 35, 38, 39, 37, 36, 42, 41, 40, 62, 58, 57, 44, 46, 45, 61, 59, 10, 9, 8, 7, 13, 12, 11, 5, 4, 22, 25, 3, 30, 15, 27, 24, 2, 28, 54, 52, 55, 51, 50, 18, 31, 34, 23, 56, 53, 20, 17, 16, 19, 47, 33, 32, 29, 21, 26, 6, 70]\n",
    "\n",
    "rbg109a.json:\n",
    "1618    mit     [0, 1, 3, 2, 8, 5, 6, 7, 4, 9, 11, 10, 22, 12, 13, 14, 15, 16, 21, 17, 18, 24, 19, 20, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 34, 35, 39, 36, 38, 40, 41, 42, 43, 44, 59, 45, 46, 47, 49, 54, 48, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 69, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 80, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 91, 89, 92, 90, 93, 94, 95, 97, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
    "\n",
    "ry48p.json:\n",
    "15691   mit     [0, 8, 37, 30, 43, 17, 35, 6, 5, 18, 26, 16, 42, 29, 36, 27, 45, 14, 11, 32, 19, 46, 20, 12, 22, 10, 39, 21, 2, 13, 24, 4, 47, 38, 31, 23, 9, 34, 44, 25, 3, 1, 41, 28, 33, 40, 15, 7, 48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die besten Werte, die mit den aktuellen Parametern erreicht werden sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br17.json:      44\n",
    "ESC25.json:     2318\n",
    "ft70.json:      42004\n",
    "rbg109a.json:   2075\n",
    "ry48p.json:     17180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf Basis der vielen Probedurchläufe und im Vergleich mit Kommilitonen und anderen Algorithmen würde ich das Potential des TabuSearch als sehr groß einschätzen. Die aktuelle Lösungsgüte mit den gewählten Parametern ist jedoch lediglich gut bis befriedigend. Für kleinere Instanzen gibt der Algorithmus schnell gute Lösungen zurück, jedoch meist nur, wenn die Startlösung bereits gut gewesen ist. Das Überwinden der lokalen Optima ist eine große Stärke, die TabuSearch mit den gewählten Paramtern und der Art der Implementierung jedoch nicht wirklich ausnutzen kann. Die Intensivierung des Algorithmus ist sehr Rechenaufwändig und die Programmierweise nicht ressourcensparend genug.<br>\n",
    "<br>\n",
    "Verwendet wurde für die Programmierung und Testung des Algorithmus ein Microsoft Surface Pro der 6. Generation mit 8GB RAM und einem Intel Core i5-8250U mit 1,6 bzw. 1,8 GHz. Dies entspricht einem Mittelklasse Office Rechner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Erläuterung:\n",
    "es gibt zwei wesentliche Paramter, die variiert werden können. Dabei handelt es sich um 1) maxTabuListLength und um 2) maxIterations.<br>\n",
    "1) Die Länge der TabuListe wird in der Literatur nicht klar bestimmt. Da Die Länge der TabuListe Cycling verhindern soll, ist sie verhältnismäßig wichtig. Es gibt verschiedene Konzepte, unteranderem wird in Glover et al. festgestellt, dass eine TabuListe proportional zur Problem Größe implementiert werden soll [2]. Außerdem wurd in [2] festgestellt, dass sich eine dynamisch ändernde TabuListen-Länge nur positiv auf das Ergebnis auswirkt. In dieser Arbeit wurde jedoch aufgrund der Reproduzierbarkeit der Lösungen darauf verzichtet und eine statische Länge implementiert: 35. Dieser Wert enstspringt experimentellen Testens, wie [3] es nahelegt. Ein zu geringer Wert riskiert, dass nach einer geringen Anzahl an Tauschen die selbe lokale beste Lösung wieder gefunden wird und die Diversifikation dadurch kaum zum Einsatz kommt. Ein zu hoher Wert könnte die Intensivierung blockieren, bessere Lösung in einer nahegelegenen Nachbarschaft zu finden. <br>\n",
    "2) Die Intensivierung der Lösungsfindung wird maßgeblich durch die Nachbarschaftssuche beeinflusst. Diese Intensivierungsphase der Lösungsfindung ist entscheidend und wird durch die maxIterations gesteuert. Diese gibt an, nach wievielen Tauschen in der Nachbarschaft die Intensivierung der Lösung abgebrochen werden soll. Ist der Wert zu hoch, benötigt der Rechner enorm lange, besonders bei größeren Mengen an Knoten (50+), und bei zu niedrigen maxIterations-Werten kann selten eine wirklich gute lokale beste Lösung gefunden werden. Es muss eine Balance dazwischen gefunden werden: 500 Iterationen liefern relativ gute Ergebnisse. Dieser Wert wurde erneut experimentell bestimmt. Als Beispiel wäre die Wahl von 1000 Iterationen bei der rbg109a.json Datei sehr unvorteilhaft, da 1000 Permutationen generiert und anschließend auf ihre Güte getestet werden. Bei dieser Menge als Rechnerleistung ist dies sehr langsam und führt dazu, dass in der vorgegebenen Zeit deutlich weniger \"neue Ansätz\" bzw. Iterationen mit der letzt-besten Permutation getätigt werden können. Es kommt am Ende ein schlechteres Ergebnis zurück als bei 500 Iterationen, die Intensivierung des Algorithmus ist zu hoch im Vergleich zur Diversifikation.\n",
    "\n",
    "<br>\n",
    "Bestimmung der Parametereinstellung nach folgender Form:<br>\n",
    "Funktionswert: Anzahl Itertationen (Parametereinstellung)<br>\n",
    "\n",
    "MaxIterations Parametereinstellungen:<br>\n",
    "<br>\n",
    "br17.json<br>\n",
    "44: 34 Iterationen (500)<br>\n",
    "44: 33 Iterationen (1000)<br>\n",
    "<br>\n",
    "ESC25.json<br>\n",
    "2318: 9 Iterationen (500)<br>\n",
    "2318: 9 Iterationen (1000)<br>\n",
    "<br>\n",
    "ry48p.json<br>\n",
    "17474: 3 Iterationen (500)<br>\n",
    "17775: 2 Iterationen (1000)<br>\n",
    "<br>\n",
    "ft70<br>\n",
    "42126: 15 Iterationen (500)<br>\n",
    "42400:  8 Iterationen (1000)<br>\n",
    "<br>\n",
    "rbg109a.json<br>\n",
    "2075: 69 Iterationen (500)<br>\n",
    "1968: 16 Iterationen (1000)<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "MaxTabuListLength:<br>\n",
    "<br>\n",
    "br17.json<br>\n",
    "44: 33 Iterationen (2)<br>\n",
    "44: 33 Iterationen (5)<br>\n",
    "44: 33 Iterationen (35)<br>\n",
    "44: 33 Iterationen (50)<br>\n",
    "<br>\n",
    "ESC25.json<br>\n",
    "2318: 8 Iterationen (2)<br>\n",
    "2318: 8 Iterationen (5)<br>\n",
    "2318: 8 Iterationen (35)<br>\n",
    "2318: 9 Iterationen (50)<br>\n",
    "<br>\n",
    "ry48p.json<br>\n",
    "17474: 3 Iterationen (2)<br>\n",
    "17474: 3 Iterationen (5)<br>\n",
    "17180: 4 Iterationen (35)<br>\n",
    "17474: 3 Iterationen (50)<br>\n",
    "<br>\n",
    "ft70.json<br>\n",
    "42126: 18 Iterationen (2)<br>\n",
    "42126: 16 Iterationen (5)<br>\n",
    "42004: 18 Iterationen (35)<br>\n",
    "42004: 19 Iterationen (50)<br>\n",
    "<br>\n",
    "rbg109a.json<br>\n",
    "2075: 34 Iterationen (2)<br>\n",
    "2075: 38 Iterationen (5)<br>\n",
    "2075: 37 Iterationen (35)<br>\n",
    "2075: 37 Iterationen (50)<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Nach dieser Parameteruntersuchung wurde sich für die folgenden Parameter entschieden:<br>\n",
    "maxIterations: 500<br>\n",
    "maxTabuSearchListLength: 35<br>\n",
    "<br>\n",
    "Erweiterungsmöglichkeiten des ALgorithmus wurden bereits angesprochen. Zum Einen gibt es die Möglichkeit, dynamische Parameter zu nutzen und die TabuListLength auf Basis der Häufigkeit der Erfassung der selben Lösung dahingegend anzupassen, dass sich die Länge immer weiter erhöht, wenn keine Verbesserungen gefunden werden können.<br>\n",
    "Zudem lässt sich das bereits eingebaute Langzeitgedächtnis mit den besten lokalen Lösungen nutzen, um von den besten bisherigen Lösungen die Suche neuzustarten, mit veränderten Parametern etc.<br>\n",
    "In der Literatur wird ebenfalls von einem mittelfristigen Gedächtnis gesprochen, mit dem gute Ergenisse noch verbessert werden könnten [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literaturverzeichnis:<br>\n",
    "<br>\n",
    "[1]: S. Basu, \"Tabu Search Implementation on Traveling Salesman Problem and Its Variations: A Litertaure Survey\", Amercian Journal of Operations Research, 2012, pp. 163-173.<br>\n",
    "[2]: F. Glover, E. Taillard, D. de Werra, \"A user's guide to tabu search\", Ann Oper Res 41, 1993, pp. 1-28.<br>\n",
    "[3]: M. Dam, M. Zachariasen, \"Tabu Search on the Geometric Traveling Saleman Problem\", Master of Science Thesis, 1994.<br>\n",
    "[4]: M. Gendreau, J.-Y. Potvin, \"Handbook of Metaheuristics, Third Edition\", Springer Cham, 2019.<br>\n",
    "<br>\n",
    "weitere Literatur, die zum Verständnis und Aufbau hinzugezogen wurde:<br>\n",
    "<br>\n",
    "[A]: A.Banerjee, D. Singh, S. Sahana, I. Nath, \"Cognitive Big Data Intelligence with a Metaheuristic Approach - Chapter 3 - Impacts of metaheuristic and swarm intelligence approach in optimization\", Academic Press, 2022, pp. 71-99.<br>\n",
    "[B]: F. Mascia, P. Pellegrini, T. Stützle, M. Birattari, \"An Analysis of Parameter Adaption in Reactive TabuSearch\", IRIDIA - Technical Report Series, Technical Report No. TR/IRIDIA/2011-026, 2016.<br>\n",
    "[C]: S. Stepanenko, \"Global Optimization Methods based on Tabu Search\", Dissertation at Julius-Maximilians-Universität Würzburg, 2008.<br>\n",
    "[D]: W. Jaziri, \"Local Search Techniques: Focus on Tabu Search\", IN TECH d.o.o., 2008.<br>\n",
    "[E]: S. Sarmady, \"An Investigation on Tabu Search Parameters\", Universiti Sains Malaysia, 2007.<br>\n",
    "[F]: F. Geyik, I. H. Cedimoglu, \"The strategies and parameters of tabu search for job-shop scheduling\", Journal of Intelligent Manufacturing, 15, 2004, pp. 439-448.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In nachfolgender Zelle ist der vollständige Algorithmus durch importe durchführbar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 160: Duration 17.60 seconds\n",
      "Iteration 16: Duration 18.04 seconds\n",
      "Iteration 240: Duration 18.76 seconds\n",
      "Iteration 48: Duration 19.47 seconds\n",
      "Iteration 64: Duration 19.99 seconds\n",
      "Iteration 192: Duration 20.10 seconds\n",
      "Iteration 176: Duration 20.43 seconds\n",
      "Iteration 208: Duration 20.34 seconds\n",
      "Iteration 32: Duration 21.08 seconds\n",
      "Iteration 96: Duration 21.03 seconds\n",
      "Iteration 80: Duration 21.29 seconds\n",
      "Iteration 112: Duration 21.54 seconds\n",
      "Iteration 224: Duration 21.27 seconds\n",
      "Iteration 144: Duration 22.35 seconds\n",
      "Iteration 128: Duration 34.83 seconds\n",
      "Iteration 193: Duration 18.31 seconds\n",
      "Iteration 161: Duration 21.85 seconds\n",
      "Iteration 241: Duration 20.92 seconds\n",
      "Iteration 81: Duration 19.66 seconds\n",
      "Iteration 49: Duration 22.28 seconds\n",
      "Iteration 65: Duration 21.96 seconds\n",
      "Iteration 97: Duration 22.62 seconds\n",
      "Iteration 113: Duration 22.53 seconds\n",
      "Iteration 209: Duration 24.34 seconds\n",
      "Iteration 177: Duration 26.55 seconds\n",
      "Iteration 17: Duration 33.19 seconds\n",
      "Iteration 33: Duration 32.02 seconds\n",
      "Iteration 145: Duration 33.37 seconds\n",
      "Iteration 129: Duration 24.31 seconds\n",
      "Iteration 225: Duration 38.50 seconds\n",
      "Iteration 242: Duration 20.95 seconds\n",
      "Iteration 194: Duration 22.62 seconds\n",
      "Iteration 162: Duration 21.95 seconds\n",
      "Iteration 66: Duration 22.11 seconds\n",
      "Iteration 98: Duration 22.97 seconds\n",
      "Iteration 210: Duration 24.12 seconds\n",
      "Iteration 82: Duration 28.33 seconds\n",
      "Iteration 50: Duration 28.38 seconds\n",
      "Iteration 114: Duration 29.07 seconds\n",
      "Iteration 18: Duration 23.30 seconds\n",
      "Iteration 34: Duration 22.37 seconds\n",
      "Iteration 146: Duration 24.33 seconds\n",
      "Iteration 178: Duration 33.37 seconds\n",
      "Iteration 226: Duration 21.58 seconds\n",
      "Iteration 195: Duration 21.67 seconds\n",
      "Iteration 130: Duration 25.00 seconds\n",
      "Iteration 67: Duration 20.93 seconds\n",
      "Iteration 243: Duration 26.98 seconds\n",
      "Iteration 163: Duration 26.71 seconds\n",
      "Iteration 211: Duration 21.92 seconds\n",
      "Iteration 115: Duration 17.87 seconds\n",
      "Iteration 83: Duration 22.78 seconds\n",
      "Iteration 51: Duration 27.47 seconds\n",
      "Iteration 35: Duration 24.60 seconds\n",
      "Iteration 227: Duration 18.54 seconds\n",
      "Iteration 179: Duration 19.38 seconds\n",
      "Iteration 99: Duration 34.02 seconds\n",
      "Iteration 147: Duration 23.82 seconds\n",
      "Iteration 19: Duration 31.88 seconds\n",
      "Iteration 68: Duration 23.06 seconds\n",
      "Iteration 164: Duration 20.29 seconds\n",
      "Iteration 196: Duration 26.50 seconds\n",
      "Iteration 116: Duration 19.33 seconds\n",
      "Iteration 131: Duration 31.49 seconds\n",
      "Iteration 244: Duration 28.33 seconds\n",
      "Iteration 212: Duration 26.05 seconds\n",
      "Iteration 84: Duration 29.62 seconds\n",
      "Iteration 228: Duration 22.09 seconds\n",
      "Iteration 180: Duration 23.95 seconds\n",
      "Iteration 52: Duration 27.79 seconds\n",
      "Iteration 36: Duration 27.48 seconds\n",
      "Iteration 100: Duration 26.87 seconds\n",
      "Iteration 197: Duration 20.89 seconds\n",
      "Iteration 148: Duration 28.73 seconds\n",
      "Iteration 69: Duration 26.72 seconds\n",
      "Iteration 117: Duration 25.00 seconds\n",
      "Iteration 165: Duration 28.07 seconds\n",
      "Iteration 213: Duration 20.12 seconds\n",
      "Iteration 245: Duration 21.75 seconds\n",
      "Iteration 132: Duration 23.73 secondsIteration 20: Duration 33.12 seconds\n",
      "\n",
      "Iteration 181: Duration 19.55 seconds\n",
      "Iteration 198: Duration 15.94 seconds\n",
      "Iteration 85: Duration 25.17 seconds\n",
      "Iteration 229: Duration 25.35 seconds\n",
      "Iteration 53: Duration 23.80 seconds\n",
      "Iteration 101: Duration 21.23 seconds\n",
      "Iteration 149: Duration 25.94 seconds\n",
      "Iteration 37: Duration 33.72 seconds\n",
      "Iteration 214: Duration 24.17 seconds\n",
      "Iteration 166: Duration 25.22 seconds\n",
      "Iteration 246: Duration 23.94 seconds\n",
      "Iteration 70: Duration 28.62 seconds\n",
      "Iteration 118: Duration 27.37 seconds\n",
      "Iteration 199: Duration 18.60 seconds\n",
      "Iteration 182: Duration 21.48 seconds\n",
      "Iteration 21: Duration 28.98 secondsIteration 133: Duration 28.84 seconds\n",
      "\n",
      "Iteration 230: Duration 31.04 seconds\n",
      "Iteration 86: Duration 34.57 seconds\n",
      "Iteration 150: Duration 25.30 seconds\n",
      "Iteration 54: Duration 35.76 seconds\n",
      "Iteration 167: Duration 25.76 seconds\n",
      "Iteration 215: Duration 26.35 seconds\n",
      "Iteration 102: Duration 38.67 seconds\n",
      "Iteration 247: Duration 34.72 secondsIteration 38: Duration 36.07 seconds\n",
      "\n",
      "Iteration 119: Duration 33.87 seconds\n",
      "Iteration 183: Duration 37.17 seconds\n",
      "Iteration 134: Duration 34.60 seconds\n",
      "Iteration 200: Duration 38.82 seconds\n",
      "Iteration 231: Duration 25.33 seconds\n",
      "Iteration 71: Duration 41.62 seconds\n",
      "Iteration 168: Duration 18.70 seconds\n",
      "Iteration 22: Duration 37.84 seconds\n",
      "Iteration 151: Duration 22.32 seconds\n",
      "Iteration 216: Duration 20.42 seconds\n",
      "Iteration 87: Duration 30.18 seconds\n",
      "Iteration 55: Duration 34.50 seconds\n",
      "Iteration 248: Duration 28.19 seconds\n",
      "Iteration 103: Duration 39.43 seconds\n",
      "Iteration 184: Duration 25.87 seconds\n",
      "Iteration 232: Duration 23.60 seconds\n",
      "Iteration 120: Duration 31.03 secondsIteration 152: Duration 21.90 seconds\n",
      "\n",
      "Iteration 135: Duration 26.03 seconds\n",
      "Iteration 39: Duration 32.82 seconds\n",
      "Iteration 72: Duration 25.69 seconds\n",
      "Iteration 169: Duration 25.32 seconds\n",
      "Iteration 201: Duration 29.62 seconds\n",
      "Iteration 217: Duration 29.47 seconds\n",
      "Iteration 23: Duration 40.50 seconds\n",
      "Iteration 153: Duration 22.05 seconds\n",
      "Iteration 185: Duration 23.45 seconds\n",
      "Iteration 249: Duration 26.07 seconds\n",
      "Iteration 56: Duration 32.82 seconds\n",
      "Iteration 88: Duration 40.92 seconds\n",
      "Iteration 233: Duration 25.20 seconds\n",
      "Iteration 121: Duration 28.97 seconds\n",
      "Iteration 136: Duration 29.37 seconds\n",
      "Iteration 170: Duration 27.58 seconds\n",
      "Iteration 104: Duration 32.11 seconds\n",
      "Iteration 218: Duration 26.63 seconds\n",
      "Iteration 202: Duration 33.43 seconds\n",
      "Iteration 40: Duration 39.30 seconds\n",
      "Iteration 73: Duration 40.05 seconds\n",
      "Iteration 154: Duration 26.35 seconds\n",
      "Iteration 186: Duration 26.95 seconds\n",
      "Iteration 250: Duration 27.19 seconds\n",
      "Iteration 234: Duration 26.53 seconds\n",
      "Iteration 24: Duration 33.38 seconds\n",
      "Iteration 57: Duration 28.48 seconds\n",
      "Iteration 89: Duration 29.36 seconds\n",
      "Iteration 171: Duration 26.63 seconds\n",
      "Iteration 137: Duration 27.49 seconds\n",
      "Iteration 122: Duration 30.10 seconds\n",
      "Iteration 105: Duration 34.67 seconds\n",
      "Iteration 219: Duration 30.79 seconds\n",
      "Iteration 203: Duration 30.22 seconds\n",
      "Iteration 74: Duration 30.37 seconds\n",
      "Iteration 41: Duration 33.43 seconds\n",
      "Iteration 155: Duration 26.56 seconds\n",
      "Iteration 251: Duration 26.83 secondsIteration 235: Duration 25.75 seconds\n",
      "Iteration 187: Duration 27.24 seconds\n",
      "\n",
      "Iteration 25: Duration 25.95 seconds\n",
      "Iteration 90: Duration 25.17 seconds\n",
      "Iteration 172: Duration 22.79 seconds\n",
      "Iteration 58: Duration 28.17 seconds\n",
      "Iteration 138: Duration 38.07 seconds\n",
      "Iteration 123: Duration 37.29 seconds\n",
      "Iteration 106: Duration 32.00 seconds\n",
      "Iteration 220: Duration 31.03 seconds\n",
      "Iteration 204: Duration 29.54 seconds\n",
      "Iteration 156: Duration 23.25 seconds\n",
      "Iteration 236: Duration 21.27 seconds\n",
      "Iteration 75: Duration 25.99 seconds\n",
      "Iteration 173: Duration 19.03 seconds\n",
      "Iteration 42: Duration 24.77 seconds\n",
      "Iteration 91: Duration 22.34 seconds\n",
      "Iteration 188: Duration 24.35 seconds\n",
      "Iteration 252: Duration 26.20 seconds\n",
      "Iteration 26: Duration 25.62 seconds\n",
      "Iteration 237: Duration 21.09 seconds\n",
      "Iteration 59: Duration 39.27 seconds\n",
      "Iteration 139: Duration 24.95 seconds\n",
      "Iteration 107: Duration 23.35 seconds\n",
      "Iteration 221: Duration 23.63 seconds\n",
      "Iteration 157: Duration 23.36 seconds\n",
      "Iteration 124: Duration 25.52 seconds\n",
      "Iteration 205: Duration 25.32 seconds\n",
      "Iteration 174: Duration 24.62 seconds\n",
      "Iteration 189: Duration 23.95 seconds\n",
      "Iteration 43: Duration 28.53 seconds\n",
      "Iteration 76: Duration 31.19 seconds\n",
      "Iteration 92: Duration 33.23 seconds\n",
      "Iteration 253: Duration 36.55 seconds\n",
      "Iteration 238: Duration 22.59 seconds\n",
      "Iteration 27: Duration 40.23 seconds\n",
      "Iteration 222: Duration 22.85 seconds\n",
      "Iteration 158: Duration 23.03 seconds\n",
      "Iteration 125: Duration 22.70 seconds\n",
      "Iteration 140: Duration 26.00 seconds\n",
      "Iteration 175: Duration 23.92 seconds\n",
      "Iteration 108: Duration 26.97 seconds\n",
      "Iteration 190: Duration 25.15 seconds\n",
      "Iteration 206: Duration 27.97 seconds\n",
      "Iteration 60: Duration 34.97 seconds\n",
      "Iteration 93: Duration 29.11 seconds\n",
      "Iteration 254: Duration 25.14 seconds\n",
      "Iteration 239: Duration 23.44 seconds\n",
      "Iteration 77: Duration 35.95 seconds\n",
      "Iteration 159: Duration 21.43 seconds\n",
      "Iteration 223: Duration 23.20 seconds\n",
      "Iteration 44: Duration 40.24 seconds\n",
      "Iteration 126: Duration 24.49 seconds\n",
      "Iteration 109: Duration 22.30 seconds\n",
      "Iteration 28: Duration 26.37 seconds\n",
      "Iteration 141: Duration 24.13 seconds\n",
      "Iteration 191: Duration 22.91 seconds\n",
      "Iteration 207: Duration 30.29 seconds\n",
      "Iteration 255: Duration 19.87 seconds\n",
      "Iteration 61: Duration 31.37 seconds\n",
      "Iteration 94: Duration 22.97 seconds\n",
      "Iteration 78: Duration 20.74 seconds\n",
      "Iteration 142: Duration 15.43 seconds\n",
      "Iteration 127: Duration 17.39 seconds\n",
      "Iteration 29: Duration 16.43 seconds\n",
      "Iteration 110: Duration 16.43 seconds\n",
      "Iteration 45: Duration 18.70 seconds\n",
      "Iteration 62: Duration 12.48 seconds\n",
      "Iteration 111: Duration 12.47 seconds\n",
      "Iteration 79: Duration 12.47 seconds\n",
      "Iteration 30: Duration 12.47 seconds\n",
      "Iteration 46: Duration 12.47 seconds\n",
      "Iteration 95: Duration 12.50 seconds\n",
      "Iteration 143: Duration 12.49 seconds\n",
      "Iteration 31: Duration 11.09 seconds\n",
      "Iteration 47: Duration 11.08 seconds\n",
      "Iteration 63: Duration 11.09 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "from InputData import *\n",
    "from EvaluationLogic import *\n",
    "from OutputData import *\n",
    "from Solver import *\n",
    "from BestStartSolution import *\n",
    "\n",
    "\n",
    "def process_scenario(start, end):\n",
    "    for i in range(start,end):\n",
    "        start_time = time.time()  # Start timing before the process begins\n",
    "\n",
    "        path = 'scenario_example_id_' + str(i) + '.json'\n",
    "        seedNumber = 50\n",
    "        maxTabuListLength = 35\n",
    "        maxIterations = 500\n",
    "\n",
    "        data = InputData(path)\n",
    "        firstSolution = BestStartSolution(data.matrix, seedNumber).generate_best_start_solution()\n",
    "\n",
    "        solution = Solver(path).tabuSearch(firstSolution, data.matrix, path, maxTabuListLength, maxIterations)\n",
    "\n",
    "        end_time = time.time()  # End timing after the process ends\n",
    "        duration = end_time - start_time  # Calculate the duration\n",
    "\n",
    "        print(f\"Iteration {i}: Duration {duration:.2f} seconds\")  # Print the duration for each iteration\n",
    "\n",
    "threads = []\n",
    "for i in range(1, 16):\n",
    "    t = threading.Thread(target=process_scenario, args=(i*16,i*16+16,))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a71a232f5bc4f832c5cb447a3a248a1ce1147aa6bcdff74c762ba6cefd89ffe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
